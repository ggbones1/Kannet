F:\mycode\pykan\kannet\Lib\site-packages\torch\nn\modules\loss.py:535: UserWarning: Using a target size (torch.Size([32, 1, 2])) that is different to the input size (torch.Size([32, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
F:\mycode\pykan\kannet\Lib\site-packages\torch\nn\modules\loss.py:535: UserWarning: Using a target size (torch.Size([12, 1, 2])) that is different to the input size (torch.Size([12, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
F:\mycode\pykan\kannet\Lib\site-packages\torch\nn\modules\loss.py:535: UserWarning: Using a target size (torch.Size([20, 1, 2])) that is different to the input size (torch.Size([20, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
Epoch 0, KAN Train Loss: 0.3645937575234307, Validation Loss: 0.3470446541905403
Epoch 1, KAN Train Loss: 0.32768260439236957, Validation Loss: 0.3309895172715187
Epoch 2, KAN Train Loss: 0.316726631588406, Validation Loss: 0.3153361827135086
Epoch 3, KAN Train Loss: 0.2964405483669705, Validation Loss: 0.30030880123376846
Epoch 4, KAN Train Loss: 0.28096211287710404, Validation Loss: 0.2862088978290558
Epoch 5, KAN Train Loss: 0.2738327615790897, Validation Loss: 0.2729378268122673
Epoch 6, KAN Train Loss: 0.25812163286738926, Validation Loss: 0.26037871092557907
Epoch 7, KAN Train Loss: 0.2496354579925537, Validation Loss: 0.24865905940532684
Epoch 8, KAN Train Loss: 0.23297844661606681, Validation Loss: 0.23757841065526009
Epoch 9, KAN Train Loss: 0.23448721733358172, Validation Loss: 0.2272360660135746
Epoch 10, KAN Train Loss: 0.21996083358923593, Validation Loss: 0.22232333198189735
Epoch 11, KAN Train Loss: 0.21278768281141916, Validation Loss: 0.21752889454364777
Epoch 12, KAN Train Loss: 0.21598945061365762, Validation Loss: 0.21288367360830307
Epoch 13, KAN Train Loss: 0.20775808725092146, Validation Loss: 0.208308357745409
Epoch 14, KAN Train Loss: 0.20117757386631435, Validation Loss: 0.2038458101451397
Epoch 15, KAN Train Loss: 0.1984733243783315, Validation Loss: 0.19950782135128975
Epoch 16, KAN Train Loss: 0.19395994477801853, Validation Loss: 0.19533219933509827
Epoch 17, KAN Train Loss: 0.1908340354760488, Validation Loss: 0.19128492847085
Epoch 18, KAN Train Loss: 0.1900605708360672, Validation Loss: 0.1873808242380619
Epoch 19, KAN Train Loss: 0.18374411430623797, Validation Loss: 0.1836036816239357
Epoch 20, KAN Train Loss: 0.18654154406653511, Validation Loss: 0.18174885585904121
Epoch 21, KAN Train Loss: 0.17885045210520426, Validation Loss: 0.17991304397583008
Epoch 22, KAN Train Loss: 0.17551896141635048, Validation Loss: 0.17808718606829643
Epoch 23, KAN Train Loss: 0.17562035057279798, Validation Loss: 0.1763262003660202
Epoch 24, KAN Train Loss: 0.17296205461025238, Validation Loss: 0.17455728724598885
Epoch 25, KAN Train Loss: 0.17477690759632322, Validation Loss: 0.17279230430722237
Epoch 26, KAN Train Loss: 0.1708684033817715, Validation Loss: 0.17104195058345795
Epoch 27, KAN Train Loss: 0.16535186767578125, Validation Loss: 0.16934696212410927
Epoch 28, KAN Train Loss: 0.16606133017275068, Validation Loss: 0.16766150668263435
Epoch 29, KAN Train Loss: 0.16476101842191485, Validation Loss: 0.16600839421153069
Epoch 30, KAN Train Loss: 0.16720439990361533, Validation Loss: 0.16518790274858475
Epoch 31, KAN Train Loss: 0.16184728178713056, Validation Loss: 0.16436365991830826
Epoch 32, KAN Train Loss: 0.16276653856039047, Validation Loss: 0.16354287043213844
Epoch 33, KAN Train Loss: 0.1639391084512075, Validation Loss: 0.16272131726145744
Epoch 34, KAN Train Loss: 0.1631403068701426, Validation Loss: 0.1619194597005844
Epoch 35, KAN Train Loss: 0.16220785511864555, Validation Loss: 0.16111097484827042
Epoch 36, KAN Train Loss: 0.15455701698859534, Validation Loss: 0.16030624136328697
Epoch 37, KAN Train Loss: 0.15485438621706432, Validation Loss: 0.15951842442154884
Epoch 38, KAN Train Loss: 0.15597177876366508, Validation Loss: 0.15874245762825012
Epoch 39, KAN Train Loss: 0.1542518792880906, Validation Loss: 0.15797463059425354
Epoch 40, KAN Train Loss: 0.15676318605740866, Validation Loss: 0.15758351981639862
Epoch 41, KAN Train Loss: 0.15882588426272073, Validation Loss: 0.15719525143504143
Epoch 42, KAN Train Loss: 0.1541328877210617, Validation Loss: 0.1568085290491581
Epoch 43, KAN Train Loss: 0.15462002240949207, Validation Loss: 0.15641698241233826
Epoch 44, KAN Train Loss: 0.15128155218230355, Validation Loss: 0.156027901917696
Epoch 45, KAN Train Loss: 0.15476343201266396, Validation Loss: 0.1556391939520836
Epoch 46, KAN Train Loss: 0.15612396597862244, Validation Loss: 0.15525299310684204
Epoch 47, KAN Train Loss: 0.15395868652396733, Validation Loss: 0.15486351773142815
Epoch 48, KAN Train Loss: 0.1549176143275367, Validation Loss: 0.1544717401266098
Epoch 49, KAN Train Loss: 0.15424375732739767, Validation Loss: 0.15408919379115105
Epoch 0, MLP Train Loss: 0.20929496155844796, Validation Loss: 0.15418521501123905
Epoch 1, MLP Train Loss: 0.15639680292871264, Validation Loss: 0.10104243271052837
Epoch 2, MLP Train Loss: 0.09277215351661046, Validation Loss: 0.055583481676876545
Epoch 3, MLP Train Loss: 0.06388936647110516, Validation Loss: 0.07205627299845219
Epoch 4, MLP Train Loss: 0.06481572820080651, Validation Loss: 0.055727445520460606
Epoch 5, MLP Train Loss: 0.0606100277768241, Validation Loss: 0.05436789710074663
Epoch 6, MLP Train Loss: 0.059451940986845225, Validation Loss: 0.055760511197149754
Epoch 7, MLP Train Loss: 0.06196484218041102, Validation Loss: 0.05554396938532591
Epoch 8, MLP Train Loss: 0.061064176675346166, Validation Loss: 0.05516134575009346
Epoch 9, MLP Train Loss: 0.06046729286511739, Validation Loss: 0.05467229522764683
Epoch 10, MLP Train Loss: 0.06006924104359415, Validation Loss: 0.054941258393228054
Epoch 11, MLP Train Loss: 0.05739340206815137, Validation Loss: 0.055393168702721596
Epoch 12, MLP Train Loss: 0.06084666152795156, Validation Loss: 0.05501829646527767
Epoch 13, MLP Train Loss: 0.058683250927262835, Validation Loss: 0.05464589782059193
Epoch 14, MLP Train Loss: 0.05863729574614101, Validation Loss: 0.054938443936407566
Epoch 15, MLP Train Loss: 0.05908928273452653, Validation Loss: 0.054460614919662476
Epoch 16, MLP Train Loss: 0.06082660663459036, Validation Loss: 0.05444217845797539
Epoch 17, MLP Train Loss: 0.05884033855464724, Validation Loss: 0.054499123245477676
Epoch 18, MLP Train Loss: 0.05894725811150339, Validation Loss: 0.05462015327066183
Epoch 19, MLP Train Loss: 0.06117799091670248, Validation Loss: 0.05532585084438324
Epoch 20, MLP Train Loss: 0.05944312198294534, Validation Loss: 0.055385698564350605
Epoch 21, MLP Train Loss: 0.05800014320347044, Validation Loss: 0.054863505996763706
Epoch 22, MLP Train Loss: 0.05768795394235187, Validation Loss: 0.05442469008266926
Epoch 23, MLP Train Loss: 0.06266098428103659, Validation Loss: 0.05440064612776041
Epoch 24, MLP Train Loss: 0.06172575636042489, Validation Loss: 0.05563402269035578
Epoch 25, MLP Train Loss: 0.060442989899052516, Validation Loss: 0.055810751393437386
Epoch 26, MLP Train Loss: 0.05919504248433643, Validation Loss: 0.05497050937265158
Epoch 27, MLP Train Loss: 0.05969173750943608, Validation Loss: 0.054671576246619225
Epoch 28, MLP Train Loss: 0.058792687124676175, Validation Loss: 0.05433752853423357
Epoch 29, MLP Train Loss: 0.0587556945780913, Validation Loss: 0.054548692889511585
Epoch 30, MLP Train Loss: 0.057042782919274435, Validation Loss: 0.05463817808777094
Epoch 31, MLP Train Loss: 0.060931330339776144, Validation Loss: 0.05463105533272028
Epoch 32, MLP Train Loss: 0.05974969971511099, Validation Loss: 0.05468608532100916
Epoch 33, MLP Train Loss: 0.05810364170206918, Validation Loss: 0.05469553917646408
Epoch 34, MLP Train Loss: 0.061044101499848895, Validation Loss: 0.054572722874581814
Epoch 35, MLP Train Loss: 0.05871512326929304, Validation Loss: 0.05490216612815857
Epoch 36, MLP Train Loss: 0.057937962727414236, Validation Loss: 0.05501188710331917
Epoch 37, MLP Train Loss: 0.057839435835679374, Validation Loss: 0.054763239808380604
Epoch 38, MLP Train Loss: 0.060834543572531805, Validation Loss: 0.05470371339470148
Epoch 39, MLP Train Loss: 0.058264238552914724, Validation Loss: 0.054848698899149895
Epoch 40, MLP Train Loss: 0.0601614365975062, Validation Loss: 0.054817887023091316
Epoch 41, MLP Train Loss: 0.059026469786961876, Validation Loss: 0.054743862710893154
Epoch 42, MLP Train Loss: 0.06007483725746473, Validation Loss: 0.05468246899545193
Epoch 43, MLP Train Loss: 0.05910116475489405, Validation Loss: 0.054733967408537865
Epoch 44, MLP Train Loss: 0.05858916665116946, Validation Loss: 0.05481315404176712
Epoch 45, MLP Train Loss: 0.05885609860221545, Validation Loss: 0.05473549943417311
Epoch 46, MLP Train Loss: 0.05931627626220385, Validation Loss: 0.05474990978837013
Epoch 47, MLP Train Loss: 0.05854280251595709, Validation Loss: 0.05463647376745939
Epoch 48, MLP Train Loss: 0.05962303653359413, Validation Loss: 0.05453654006123543
Epoch 49, MLP Train Loss: 0.058908580905861326, Validation Loss: 0.05454447865486145
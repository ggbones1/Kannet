{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集样本数: 307\n",
      "测试集样本数: 77\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from kan import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch.optim as optim\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_and_validate_model(model, epochs, learning_rate, train_loader, val_loader, model_name):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            predicted_y = model(x)\n",
    "            loss = loss_fn(predicted_y, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                predicted_y = model(x)\n",
    "                val_loss = loss_fn(predicted_y, y.unsqueeze(1))\n",
    "                total_val_loss += val_loss.item()\n",
    "        \n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        print(f\"Epoch {epoch}, {model_name} Train Loss: {avg_loss}, Validation Loss: {avg_val_loss}\")\n",
    "# Evaluation function\n",
    "def evaluate_model(model, eval_loader, model_name):\n",
    "    model.eval()\n",
    "    predictions, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in eval_loader:\n",
    "            predicted_y = model(x)\n",
    "            predictions.extend(predicted_y.squeeze().cpu().numpy())\n",
    "            actuals.extend(y.cpu().numpy())\n",
    "    return predictions, actuals\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取xlsx文件\n",
    "file_path = 'D:\\OneDrive - Officials\\OneDrive - Mraz Cindy\\done\\毕设资料\\计算公式说明\\数据库.xlsx'  # 替换为你的xlsx文件路径\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "\n",
    "# 打乱行顺序并按8:2的比例分成训练集和测试集\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# 提取第2，3，4，5列的数据\n",
    "input = train_df.iloc[:, 1:5]\n",
    "output = train_df.iloc[:, 5:7]\n",
    "test_input = test_df.iloc[:, 1:5]\n",
    "test_label = test_df.iloc[:, 5:7]\n",
    "# 将DataFrame转换为numpy数组并调整其维度为4\n",
    "array1 = input.to_numpy()\n",
    "array2 = output.to_numpy()\n",
    "array3 = test_input.to_numpy()\n",
    "array4 = test_label.to_numpy()\n",
    "input=torch.tensor(array1, dtype=torch.float32)\n",
    "ouput=torch.tensor(array2, dtype=torch.float32)\n",
    "test_input=torch.tensor(array3, dtype=torch.float32)\n",
    "test_label=torch.tensor(array4, dtype=torch.float32)\n",
    "def normalize_columns(tensor):\n",
    "    # 确保输入是2D张量\n",
    "    assert tensor.dim() == 2, \"Input tensor must be 2D\"\n",
    "    \n",
    "    # 获取最小值和最大值\n",
    "    col_min = tensor.min(dim=0, keepdim=True).values\n",
    "    col_max = tensor.max(dim=0, keepdim=True).values\n",
    "    \n",
    "    # 防止除以零的情况\n",
    "    denom = col_max - col_min\n",
    "    denom[denom == 0] = 1  # 如果列中所有值相等，避免除以零\n",
    "    \n",
    "    # 进行归一化\n",
    "    normalized_tensor = (tensor - col_min) / denom\n",
    "    return normalized_tensor\n",
    "# 对每一列进行归一化\n",
    "input= normalize_columns(input)\n",
    "ouput= normalize_columns(ouput)\n",
    "test_input= normalize_columns(test_input)\n",
    "test_label= normalize_columns(test_label)\n",
    "dataset={'train_input':input,'test_input':test_input,'train_label':ouput,'test_label':test_label}\n",
    "\n",
    "# 输出结果\n",
    "print(\"训练集样本数:\", len(train_df))\n",
    "print(\"测试集样本数:\", len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\mycode\\pykan\\kannet\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([32, 1, 2])) that is different to the input size (torch.Size([32, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "f:\\mycode\\pykan\\kannet\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([12, 1, 2])) that is different to the input size (torch.Size([12, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "f:\\mycode\\pykan\\kannet\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([20, 1, 2])) that is different to the input size (torch.Size([20, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, KAN Train Loss: 0.31965622305870056, Validation Loss: 0.3475344628095627\n",
      "Epoch 1, KAN Train Loss: 0.311971300178104, Validation Loss: 0.3193218782544136\n",
      "Epoch 2, KAN Train Loss: 0.294025225771798, Validation Loss: 0.29874108731746674\n",
      "Epoch 3, KAN Train Loss: 0.2668324675824907, Validation Loss: 0.28423113375902176\n",
      "Epoch 4, KAN Train Loss: 0.2636200471056832, Validation Loss: 0.2692265138030052\n",
      "Epoch 5, KAN Train Loss: 0.25179201198948753, Validation Loss: 0.2573227658867836\n",
      "Epoch 6, KAN Train Loss: 0.24516546229521433, Validation Loss: 0.25099003314971924\n",
      "Epoch 7, KAN Train Loss: 0.2414676480823093, Validation Loss: 0.24797654151916504\n",
      "Epoch 8, KAN Train Loss: 0.23348383439911735, Validation Loss: 0.24214094504714012\n",
      "Epoch 9, KAN Train Loss: 0.22539305355813768, Validation Loss: 0.2403564676642418\n",
      "Epoch 10, KAN Train Loss: 0.21867360174655914, Validation Loss: 0.23682114481925964\n",
      "Epoch 11, KAN Train Loss: 0.2181004004346, Validation Loss: 0.236090250313282\n",
      "Epoch 12, KAN Train Loss: 0.21429333918624455, Validation Loss: 0.23423166573047638\n",
      "Epoch 13, KAN Train Loss: 0.21818972958458793, Validation Loss: 0.23439894244074821\n",
      "Epoch 14, KAN Train Loss: 0.21185370286305746, Validation Loss: 0.23310783132910728\n",
      "Epoch 15, KAN Train Loss: 0.21450649367438424, Validation Loss: 0.23221584782004356\n",
      "Epoch 16, KAN Train Loss: 0.2145166496435801, Validation Loss: 0.2289593555033207\n",
      "Epoch 17, KAN Train Loss: 0.20935802161693573, Validation Loss: 0.22619763761758804\n",
      "Epoch 18, KAN Train Loss: 0.20264095233546364, Validation Loss: 0.22360945120453835\n",
      "Epoch 19, KAN Train Loss: 0.21067723631858826, Validation Loss: 0.22301742434501648\n",
      "Epoch 20, KAN Train Loss: 0.2098925295803282, Validation Loss: 0.22272495552897453\n",
      "Epoch 21, KAN Train Loss: 0.20666107204225329, Validation Loss: 0.22340022772550583\n",
      "Epoch 22, KAN Train Loss: 0.20460787581072915, Validation Loss: 0.2236889861524105\n",
      "Epoch 23, KAN Train Loss: 0.212198739250501, Validation Loss: 0.22358660772442818\n",
      "Epoch 24, KAN Train Loss: 0.20850618514749739, Validation Loss: 0.22182292491197586\n",
      "Epoch 25, KAN Train Loss: 0.20994379288620418, Validation Loss: 0.22139055654406548\n",
      "Epoch 26, KAN Train Loss: 0.20321402119265664, Validation Loss: 0.22114955261349678\n",
      "Epoch 27, KAN Train Loss: 0.20720773273044163, Validation Loss: 0.2208877019584179\n",
      "Epoch 28, KAN Train Loss: 0.20973335372077095, Validation Loss: 0.22062662988901138\n",
      "Epoch 29, KAN Train Loss: 0.2062141630384657, Validation Loss: 0.22036274150013924\n",
      "Epoch 30, KAN Train Loss: 0.20769347250461578, Validation Loss: 0.2202277109026909\n",
      "Epoch 31, KAN Train Loss: 0.20575680832068124, Validation Loss: 0.2200935259461403\n",
      "Epoch 32, KAN Train Loss: 0.20335647794935438, Validation Loss: 0.21996084600687027\n",
      "Epoch 33, KAN Train Loss: 0.20278173353936937, Validation Loss: 0.2198287956416607\n",
      "Epoch 34, KAN Train Loss: 0.2034319175614251, Validation Loss: 0.21969649568200111\n",
      "Epoch 35, KAN Train Loss: 0.205839388900333, Validation Loss: 0.2195596992969513\n",
      "Epoch 36, KAN Train Loss: 0.206634650627772, Validation Loss: 0.21943245083093643\n",
      "Epoch 37, KAN Train Loss: 0.2066908578077952, Validation Loss: 0.21929818019270897\n",
      "Epoch 38, KAN Train Loss: 0.19994411534733242, Validation Loss: 0.21915939450263977\n",
      "Epoch 39, KAN Train Loss: 0.19988559848732418, Validation Loss: 0.21901918575167656\n",
      "Epoch 40, KAN Train Loss: 0.20159131288528442, Validation Loss: 0.21894992142915726\n",
      "Epoch 41, KAN Train Loss: 0.19808124833636814, Validation Loss: 0.2188774161040783\n",
      "Epoch 42, KAN Train Loss: 0.20637869834899902, Validation Loss: 0.218805480748415\n",
      "Epoch 43, KAN Train Loss: 0.20040961934460533, Validation Loss: 0.21873296052217484\n",
      "Epoch 44, KAN Train Loss: 0.20199040406280094, Validation Loss: 0.21866105869412422\n",
      "Epoch 45, KAN Train Loss: 0.20278453164630467, Validation Loss: 0.21858788654208183\n",
      "Epoch 46, KAN Train Loss: 0.20401846369107565, Validation Loss: 0.21851401776075363\n",
      "Epoch 47, KAN Train Loss: 0.20103206071588728, Validation Loss: 0.2184411883354187\n",
      "Epoch 48, KAN Train Loss: 0.20152725941605037, Validation Loss: 0.21836785599589348\n",
      "Epoch 49, KAN Train Loss: 0.20554851161109078, Validation Loss: 0.21829643473029137\n"
     ]
    }
   ],
   "source": [
    "from KACnet import KAC_Net\n",
    "\n",
    "dimension=4\n",
    "# Define model layers\n",
    "layers = [dimension, 9, 5, 2]\n",
    "x_data=torch.cat((input,test_input),0)\n",
    "y_data=torch.cat((ouput,test_label),0)\n",
    "\n",
    "# 定义一个TensorDataset对象，将x_data和y_data传入\n",
    "dataset = TensorDataset(x_data, y_data)\n",
    "# 计算训练集和验证集的数量\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "# 将数据集划分为训练集和验证集\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "# 创建训练集的DataLoader对象，批量大小为32，打乱数据\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# 创建验证集的DataLoader对象，批量大小为32，不打乱数据\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Initialize and train the KAN model\n",
    "kan_model = KAC_Net(layers)\n",
    "train_and_validate_model(kan_model, epochs=50, learning_rate=0.001, train_loader=train_loader, val_loader=val_loader, model_name=f\"KAN\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KAC_Net' object has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mkan_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m()\n",
      "File \u001b[1;32mf:\\mycode\\pykan\\kannet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1709\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1709\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KAC_Net' object has no attribute 'plot'"
     ]
    }
   ],
   "source": [
    "kan_model.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
